{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, activation, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    Perform Froward propagation over a convolution layer.\n",
    "\n",
    "    A_prev is a numpy.ndarray of shape (m, h_prev, w_prev, c_prev)\n",
    "        containing the output of the previous layer\n",
    "        m is the number of examples\n",
    "        h_prev is the height of the previous layer\n",
    "        w_prev is the width of the previous layer\n",
    "        c_prev is the number of channels in the previous layer\n",
    "\n",
    "    W is a numpy.ndarray of shape (kh, kw, c_prev, c_new)\n",
    "    containing the kernels for the convolution\n",
    "        kh is the filter height\n",
    "        kw is the filter width\n",
    "        c_prev is the number of channels in the previous layer\n",
    "        c_new is the number of channels in the output\n",
    "\n",
    "    b is a numpy.ndarray of shape (1, 1, 1, c_new) containing\n",
    "    the biases applied to the convolution\n",
    "\n",
    "    activation is an activation function applied to the convolution\n",
    "\n",
    "    padding is a string that is either same or valid,\n",
    "    indicating the type of padding used\n",
    "\n",
    "    stride is a tuple of (sh, sw) containing the strides for the convolution\n",
    "        sh is the stride for the height\n",
    "        sw is the stride for the width\n",
    "    \"\"\"\n",
    "    m, h, w, _ = A_prev.shape\n",
    "    kh, kw, _, nc = W.shape\n",
    "    sh, sw = stride\n",
    "    if padding == 'valid':\n",
    "        ph, pw = 0, 0\n",
    "    else:\n",
    "        ph = int(np.ceil((sh*(h-1)-h+kh)/2))\n",
    "        pw = int(np.ceil((sw*(w-1)-w+kw)/2))\n",
    "    oh = int((h+2*pw-kh)/sh+1)\n",
    "    ow = int((w+2*pw-kw)/sw+1)\n",
    "    npad = ((0, 0), (ph, ph), (pw, pw), (0, 0))\n",
    "    A_pad = np.pad(A_prev, pad_width=npad, mode='constant')\n",
    "    output = np.zeros((m, oh, ow, nc))\n",
    "    for k in range(nc):\n",
    "        filterk = W[:, :, :, k]\n",
    "        for i in range(oh):\n",
    "            for j in range(ow):\n",
    "                x = i * sh\n",
    "                y = j * sw\n",
    "                to_conv = A_pad[:, x:x+kh, y:y+kw, :]\n",
    "                output[:, i, j, k] = np.tensordot(to_conv, filterk, axes=3)\n",
    "\n",
    "    output = activation(output + b)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "A = conv_forward(X_train_c, W, b, relu, padding='same')\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pool_forward(A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"\n",
    "    Perform forward propagation.\n",
    "\n",
    "    A_prev is a numpy.ndarray of shape (m, h_prev, w_prev, c_prev)\n",
    "    containing the output of the previous layer\n",
    "        m is the number of examples\n",
    "        h_prev is the height of the previous layer\n",
    "        w_prev is the width of the previous layer\n",
    "        c_prev is the number of channels in the previous layer\n",
    "    kernel_shape is a tuple of (kh, kw) containing the\n",
    "    size of the kernel for the pooling\n",
    "        kh is the kernel height\n",
    "        kw is the kernel width\n",
    "    stride is a tuple of (sh, sw) containing the strides for the pooling\n",
    "        sh is the stride for the height\n",
    "        sw is the stride for the width\n",
    "    mode is a string containing either max or avg, indicating whether\n",
    "    to perform maximum or average pooling, respectively\n",
    "    \"\"\"\n",
    "    kh, kw = kernel_shape\n",
    "    sh, sw = stride\n",
    "    m, h, w, c = A_prev.shape\n",
    "    if mode == 'max':\n",
    "        func = np.max\n",
    "    elif mode == 'avg':\n",
    "        func = np.average\n",
    "\n",
    "    oh = int((h-kh)/sh+1)\n",
    "    ow = int((w-kw)/sw+1)\n",
    "    output = np.zeros((m, oh, ow, c))\n",
    "    for i in range(0, oh):\n",
    "        x = i * sh\n",
    "        for j in range(0, ow):\n",
    "            y = j * sw\n",
    "            output[:, i, j, :] = func(A_prev[:, x:x+kh, y:y+kw], axis=(1, 2))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_a = X_train.reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "print(X_train_c.shape)\n",
    "plt.imshow(X_train_c[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_train_c[0, :, :, 1])\n",
    "plt.show()\n",
    "A = pool_forward(X_train_c, (2, 2), stride=(2, 2))\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_backward(dZ, A_prev, W, b, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"Backward propagation for Conv layer.\"\"\"\n",
    "    m, prev_h, prev_w, _ = A_prev.shape\n",
    "    m, new_h, new_w, new_c = dZ.shape\n",
    "    sh, sw = stride\n",
    "    kh, kw, _, new_c = W.shape\n",
    "    if padding == 'valid':\n",
    "        ph, pw = 0, 0\n",
    "    else:\n",
    "        ph = int(np.ceil((sh*(prev_h-1)-prev_h+kh)/2))\n",
    "        pw = int(np.ceil((sw*(prev_w-1)-prev_w+kw)/2))\n",
    "    npad = ((0, 0), (ph, ph), (pw, pw), (0, 0))\n",
    "    A_prev = np.pad(A_prev, pad_width=npad, mode='constant')\n",
    "    dw = np.zeros_like(W)\n",
    "    dA = np.zeros_like(A_prev)\n",
    "    db = np.sum(dZ, axis=(0, 1, 2), keepdims=True)\n",
    "    for img in range(m):\n",
    "        for h in range(new_h):\n",
    "            for w in range(new_w):\n",
    "                x = h * sh\n",
    "                y = w * sw\n",
    "                for f in range(new_c):\n",
    "                    filt = W[:, :, :, f]\n",
    "                    dz = dZ[img, h, w, f]\n",
    "                    slice_A = A_prev[img, x:x+kh, y:y+kw,:]\n",
    "                    dw[:, :, :, f] += slice_A * dz\n",
    "                    dA[img, x:x+kh, y:y+kw,:] += dz * filt\n",
    "                    \n",
    "    if padding == 'same':\n",
    "        dA = dA[:, ph:-ph, pw:-pw, :]\n",
    "    return dA, dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "_, h, w = X_train.shape\n",
    "X_train_c = X_train[:10].reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "dZ = np.random.randn(10, h - 2, w - 2, 2)\n",
    "print(conv_backward(dZ, X_train_c, W, b, padding=\"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pool_backward(dA, A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"Performs back propagation over a pooling layer of a neural network.\"\"\"\n",
    "    kh, kw = kernel_shape\n",
    "    sh, sw = stride\n",
    "    # m, h, w, c = A_prev.shape\n",
    "    m, n_h, n_w, n_c = dA.shape\n",
    "    dA_prev = np.zeros_like(A_prev)\n",
    "\n",
    "    for img in range(m):\n",
    "        for i in range(n_h):\n",
    "            for j in range(n_w):\n",
    "                x = i * sh\n",
    "                y = j * sw\n",
    "                for k in range(n_c):\n",
    "                    if mode == 'max':\n",
    "                        a_prev_s = A_prev[img, x:x+kh, y:y+kw, k]\n",
    "                        mask = (a_prev_s == np.max(a_prev_s))\n",
    "                        dA_prev[img, x:x+kh, y:y+kw, k] += mask*dA[img, i, j, k]\n",
    "                    else:\n",
    "                        average_dA = dA[img,i,j,k]/(n_h*n_w)\n",
    "                        mask = np.ones((kh, kw))\n",
    "                        dA_prev[img, x:x+kh, y:y+kw, k] += mask*average_dA\n",
    "\n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "_, h, w = X_train.shape\n",
    "X_train_a = X_train[:10].reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "dA = np.random.randn(10, h // 3, w // 3, 2)\n",
    "print(pool_backward(dA, X_train_c, (3, 3), stride=(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "def create_pooling_layer(prev, size, stride):\n",
    "    \"\"\"Create pooling layer.\"\"\"\n",
    "    layer = tf.layers.MaxPooling2D(size, stride)\n",
    "    return layer(prev)\n",
    "\n",
    "\n",
    "def create_conv_layer(prev, size, padding, stride):\n",
    "    \"\"\"Create Conv layer.\"\"\"\n",
    "    weight = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "    layer = tf.layers.Conv2D(filters=size[2],\n",
    "                             kernel_size=(size[0], size[1]), strides=stride,\n",
    "                             padding=padding, kernel_initializer=weight)\n",
    "    return layer(prev)\n",
    "\n",
    "\n",
    "def create_normal_layer(prev, n, activation):\n",
    "    \"\"\"Create tensorflow layer.\"\"\"\n",
    "    weight = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "    layer = tf.layers.Dense(n, activation=activation, name=\"layer\",\n",
    "                                  kernel_initializer=weight)\n",
    "    return layer(prev)\n",
    "\n",
    "\n",
    "def conv_forward_prop(x, conv_sizes=[], padding=[], pool_sizes=[], strides=[]):\n",
    "    \"\"\"Convolution forward propagation.\"\"\"\n",
    "    xi = None\n",
    "    for conv, pad, pool, stride in zip(conv_sizes, padding,\n",
    "                                       pool_sizes, strides):\n",
    "        xi = create_conv_layer(x, conv, pad, stride[0])\n",
    "        xi = create_pooling_layer(xi, pool, stride[1])\n",
    "        x = xi\n",
    "    return xi\n",
    "\n",
    "\n",
    "def forward_prop(x, layer_sizes=[], activations=[]):\n",
    "    \"\"\"Forward propagation.\"\"\"\n",
    "    xi = None\n",
    "    for layer, activation in zip(layer_sizes, activations):\n",
    "        xi = create_normal_layer(x, layer, activation)\n",
    "        x = xi\n",
    "    return xi\n",
    "\n",
    "\n",
    "def calculate_loss(y, y_pred):\n",
    "    \"\"\"Calculate cross entropy loss.\"\"\"\n",
    "    return tf.losses.softmax_cross_entropy(y, y_pred)\n",
    "\n",
    "\n",
    "def calculate_accuracy(y, y_pred):\n",
    "    \"\"\"Accuracy of prediction.\"\"\"\n",
    "    y = tf.argmax(y, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    correct = tf.equal(y, y_pred)\n",
    "    return tf.reduce_mean(tf.cast(correct, dtype='float'))\n",
    "\n",
    "\n",
    "def create_train_op(loss):\n",
    "    \"\"\"Create training operation.\"\"\"\n",
    "    train = tf.train.AdamOptimizer()\n",
    "    grads = train.compute_gradients(loss)\n",
    "    return train.apply_gradients(grads)\n",
    "\n",
    "\n",
    "def lenet5(x, y):\n",
    "    \"\"\"\n",
    "    Build a modified LeNet-5 model for number recognition.\n",
    "\n",
    "    x is a tf.placeholder of shape (m, 28, 28, 1)\n",
    "    containing the input images for the network\n",
    "        m is the number of images\n",
    "    y is a tf.placeholder of shape (m, 10)\n",
    "    containing the one-hot labels for the network\n",
    "    \"\"\"\n",
    "    conv_sizes = [(5, 5, 6), (5, 5, 16)]\n",
    "    pool_sizes = [(2, 2), (2, 2)]\n",
    "    strides = [((1, 1), (2, 2)), ((1, 1), (2, 2))]\n",
    "    paddings = ['same', 'valid']\n",
    "    layer_sizes = [120, 84, 10]\n",
    "    activations = ['relu', 'relu', 'softmax']\n",
    "    y_conv = conv_forward_prop(x, conv_sizes, paddings, pool_sizes, strides)\n",
    "    x_flat = tf.layers.Flatten()(y_conv)\n",
    "    y_pred = forward_prop(x_flat, layer_sizes, activations)\n",
    "    accuracy = calculate_accuracy(y, y_pred)\n",
    "    loss = calculate_loss(y, y_pred)\n",
    "    train_op = create_train_op(loss)\n",
    "\n",
    "    return y_pred, train_op, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epochs: 2.3022689819335938 cost, 0.13001999258995056 accuracy, 2.298532485961914 validation cost, 0.13019999861717224 validation accuracy\n",
      "After 1 epochs: 1.5880002975463867 cost, 0.872439980506897 accuracy, 1.5809589624404907 validation cost, 0.8799999952316284 validation accuracy\n",
      "After 2 epochs: 1.581747055053711 cost, 0.8787000179290771 accuracy, 1.5787707567214966 validation cost, 0.882099986076355 validation accuracy\n",
      "After 3 epochs: 1.5814365148544312 cost, 0.8786799907684326 accuracy, 1.5797611474990845 validation cost, 0.880299985408783 validation accuracy\n",
      "After 4 epochs: 1.487547516822815 cost, 0.9736199975013733 accuracy, 1.4878511428833008 validation cost, 0.9739999771118164 validation accuracy\n",
      "After 5 epochs: 1.4839224815368652 cost, 0.9773399829864502 accuracy, 1.4869685173034668 validation cost, 0.9742000102996826 validation accuracy\n",
      "After 6 epochs: 1.4798390865325928 cost, 0.981440007686615 accuracy, 1.482581615447998 validation cost, 0.9786999821662903 validation accuracy\n",
      "After 7 epochs: 1.4800333976745605 cost, 0.9810799956321716 accuracy, 1.4831866025924683 validation cost, 0.9776999950408936 validation accuracy\n",
      "After 8 epochs: 1.4804826974868774 cost, 0.9807599782943726 accuracy, 1.4831454753875732 validation cost, 0.9782999753952026 validation accuracy\n",
      "After 9 epochs: 1.4842541217803955 cost, 0.9767600297927856 accuracy, 1.4864088296890259 validation cost, 0.9745000004768372 validation accuracy\n",
      "After 10 epochs: 1.4802424907684326 cost, 0.9809200167655945 accuracy, 1.4859468936920166 validation cost, 0.9753000140190125 validation accuracy\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.disable_eager_execution()\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "Y_train = lib['Y_train']\n",
    "X_valid = lib['X_valid']\n",
    "Y_valid = lib['Y_valid']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "X_valid_c = X_valid.reshape((-1, h, w, 1))\n",
    "x = tf.placeholder(tf.float32, (None, h, w, 1))\n",
    "y = tf.placeholder(tf.int32, (None,))\n",
    "y_oh = tf.one_hot(y, 10)\n",
    "y_pred, train_op, loss, acc = lenet5(x, y_oh)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "        cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "        print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epoch, cost, accuracy, cost_valid, accuracy_valid))\n",
    "        p = np.random.permutation(m)\n",
    "        X_shuffle = X_train_c[p]\n",
    "        Y_shuffle = Y_train[p]\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffle[i:i+batch_size]\n",
    "            Y_batch = Y_shuffle[i:i+batch_size]\n",
    "            sess.run(train_op, feed_dict={x:X_batch, y:Y_batch})\n",
    "    cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "    cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epochs, cost, accuracy, cost_valid, accuracy_valid))\n",
    "    Y_pred = sess.run(y_pred, feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(Y_pred[0])\n",
    "    Y_pred = np.argmax(Y_pred, 1)\n",
    "    plt.imshow(X_valid[0])\n",
    "    plt.title(str(Y_valid[0]) + ' : ' + str(Y_pred[0]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('holbertonschool-machine_learning-zF0IEfUY')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1bb7f88ff86f8a65293f6958f33bcf6ed9c9a574270708a89302acb2663e3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
