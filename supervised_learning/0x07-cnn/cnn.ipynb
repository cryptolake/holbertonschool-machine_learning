{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, activation, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    Perform Froward propagation over a convolution layer.\n",
    "\n",
    "    A_prev is a numpy.ndarray of shape (m, h_prev, w_prev, c_prev)\n",
    "        containing the output of the previous layer\n",
    "        m is the number of examples\n",
    "        h_prev is the height of the previous layer\n",
    "        w_prev is the width of the previous layer\n",
    "        c_prev is the number of channels in the previous layer\n",
    "\n",
    "    W is a numpy.ndarray of shape (kh, kw, c_prev, c_new)\n",
    "    containing the kernels for the convolution\n",
    "        kh is the filter height\n",
    "        kw is the filter width\n",
    "        c_prev is the number of channels in the previous layer\n",
    "        c_new is the number of channels in the output\n",
    "\n",
    "    b is a numpy.ndarray of shape (1, 1, 1, c_new) containing\n",
    "    the biases applied to the convolution\n",
    "\n",
    "    activation is an activation function applied to the convolution\n",
    "\n",
    "    padding is a string that is either same or valid,\n",
    "    indicating the type of padding used\n",
    "\n",
    "    stride is a tuple of (sh, sw) containing the strides for the convolution\n",
    "        sh is the stride for the height\n",
    "        sw is the stride for the width\n",
    "    \"\"\"\n",
    "    m, h, w, _ = A_prev.shape\n",
    "    kh, kw, _, nc = W.shape\n",
    "    sh, sw = stride\n",
    "    if padding == 'valid':\n",
    "        ph, pw = 0, 0\n",
    "    else:\n",
    "        ph = int(np.ceil((sh*(h-1)-h+kh)/2))\n",
    "        pw = int(np.ceil((sw*(w-1)-w+kw)/2))\n",
    "    oh = int((h+2*pw-kh)/sh+1)\n",
    "    ow = int((w+2*pw-kw)/sw+1)\n",
    "    npad = ((0, 0), (ph, ph), (pw, pw), (0, 0))\n",
    "    A_pad = np.pad(A_prev, pad_width=npad, mode='constant')\n",
    "    output = np.zeros((m, oh, ow, nc))\n",
    "    for k in range(nc):\n",
    "        filterk = W[:, :, :, k]\n",
    "        for i in range(oh):\n",
    "            for j in range(ow):\n",
    "                x = i * sh\n",
    "                y = j * sw\n",
    "                to_conv = A_pad[:, x:x+kh, y:y+kw, :]\n",
    "                output[:, i, j, k] = np.tensordot(to_conv, filterk, axes=3)\n",
    "\n",
    "    output = activation(output + b)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "A = conv_forward(X_train_c, W, b, relu, padding='same')\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pool_forward(A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"\n",
    "    Perform forward propagation.\n",
    "\n",
    "    A_prev is a numpy.ndarray of shape (m, h_prev, w_prev, c_prev)\n",
    "    containing the output of the previous layer\n",
    "        m is the number of examples\n",
    "        h_prev is the height of the previous layer\n",
    "        w_prev is the width of the previous layer\n",
    "        c_prev is the number of channels in the previous layer\n",
    "    kernel_shape is a tuple of (kh, kw) containing the\n",
    "    size of the kernel for the pooling\n",
    "        kh is the kernel height\n",
    "        kw is the kernel width\n",
    "    stride is a tuple of (sh, sw) containing the strides for the pooling\n",
    "        sh is the stride for the height\n",
    "        sw is the stride for the width\n",
    "    mode is a string containing either max or avg, indicating whether\n",
    "    to perform maximum or average pooling, respectively\n",
    "    \"\"\"\n",
    "    kh, kw = kernel_shape\n",
    "    sh, sw = stride\n",
    "    m, h, w, c = A_prev.shape\n",
    "    if mode == 'max':\n",
    "        func = np.max\n",
    "    elif mode == 'avg':\n",
    "        func = np.average\n",
    "\n",
    "    oh = int((h-kh)/sh+1)\n",
    "    ow = int((w-kw)/sw+1)\n",
    "    output = np.zeros((m, oh, ow, c))\n",
    "    for i in range(0, oh):\n",
    "        x = i * sh\n",
    "        for j in range(0, ow):\n",
    "            y = j * sw\n",
    "            output[:, i, j, :] = func(A_prev[:, x:x+kh, y:y+kw], axis=(1, 2))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_a = X_train.reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "print(X_train_c.shape)\n",
    "plt.imshow(X_train_c[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_train_c[0, :, :, 1])\n",
    "plt.show()\n",
    "A = pool_forward(X_train_c, (2, 2), stride=(2, 2))\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_backward(dZ, A_prev, W, b, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"Backward propagation for Conv layer.\"\"\"\n",
    "    m, prev_h, prev_w, _ = A_prev.shape\n",
    "    m, new_h, new_w, new_c = dZ.shape\n",
    "    sh, sw = stride\n",
    "    kh, kw, _, new_c = W.shape\n",
    "    if padding == 'valid':\n",
    "        ph, pw = 0, 0\n",
    "    else:\n",
    "        ph = int(np.ceil((sh*(prev_h-1)-prev_h+kh)/2))\n",
    "        pw = int(np.ceil((sw*(prev_w-1)-prev_w+kw)/2))\n",
    "    npad = ((0, 0), (ph, ph), (pw, pw), (0, 0))\n",
    "    A_prev = np.pad(A_prev, pad_width=npad, mode='constant')\n",
    "    dw = np.zeros_like(W)\n",
    "    dA = np.zeros_like(A_prev)\n",
    "    db = np.sum(dZ, axis=(0, 1, 2), keepdims=True)\n",
    "    for img in range(m):\n",
    "        for h in range(new_h):\n",
    "            for w in range(new_w):\n",
    "                x = h * sh\n",
    "                y = w * sw\n",
    "                for f in range(new_c):\n",
    "                    filt = W[:, :, :, f]\n",
    "                    dz = dZ[img, h, w, f]\n",
    "                    slice_A = A_prev[img, x:x+kh, y:y+kw,:]\n",
    "                    dw[:, :, :, f] += slice_A * dz\n",
    "                    dA[img, x:x+kh, y:y+kw,:] += dz * filt\n",
    "                    \n",
    "    if padding == 'same':\n",
    "        dA = dA[:, ph:-ph, pw:-pw, :]\n",
    "    return dA, dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "_, h, w = X_train.shape\n",
    "X_train_c = X_train[:10].reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "dZ = np.random.randn(10, h - 2, w - 2, 2)\n",
    "print(conv_backward(dZ, X_train_c, W, b, padding=\"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pool_backward(dA, A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"Performs back propagation over a pooling layer of a neural network.\"\"\"\n",
    "    kh, kw = kernel_shape\n",
    "    sh, sw = stride\n",
    "    # m, h, w, c = A_prev.shape\n",
    "    m, n_h, n_w, n_c = dA.shape\n",
    "    dA_prev = np.zeros_like(A_prev)\n",
    "\n",
    "    for img in range(m):\n",
    "        for i in range(n_h):\n",
    "            for j in range(n_w):\n",
    "                x = i * sh\n",
    "                y = j * sw\n",
    "                for k in range(n_c):\n",
    "                    if mode == 'max':\n",
    "                        a_prev_s = A_prev[img, x:x+kh, y:y+kw, k]\n",
    "                        mask = (a_prev_s == np.max(a_prev_s))\n",
    "                        dA_prev[img, x:x+kh, y:y+kw, k] += mask*dA[img, i, j, k]\n",
    "                    else:\n",
    "                        average_dA = dA[img,i,j,k]/(n_h*n_w)\n",
    "                        mask = np.ones((kh, kw))\n",
    "                        dA_prev[img, x:x+kh, y:y+kw, k] += mask*average_dA\n",
    "\n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "_, h, w = X_train.shape\n",
    "X_train_a = X_train[:10].reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "dA = np.random.randn(10, h // 3, w // 3, 2)\n",
    "print(pool_backward(dA, X_train_c, (3, 3), stride=(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "def calculate_accuracy(y, y_pred):\n",
    "    \"\"\"Accuracy of prediction.\"\"\"\n",
    "    y = tf.argmax(y, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    correct = tf.equal(y, y_pred)\n",
    "    return tf.reduce_mean(tf.cast(correct, dtype='float'))\n",
    "\n",
    "\n",
    "def lenet5(x, y):\n",
    "    \"\"\"\n",
    "    Build a modified LeNet-5 model for number recognition.\n",
    "\n",
    "    x is a tf.placeholder of shape (m, 28, 28, 1)\n",
    "    containing the input images for the network\n",
    "        m is the number of images\n",
    "    y is a tf.placeholder of shape (m, 10)\n",
    "    containing the one-hot labels for the network\n",
    "    \"\"\"\n",
    "    init = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "    x1 = tf.layers.Conv2D(filters=6, kernel_size=5, padding='same',\n",
    "                          kernel_initializer=init, activation='relu')(x)\n",
    "    px1 = tf.layers.MaxPooling2D(2, 2)(x1)\n",
    "    x2 = tf.layers.Conv2D(filters=16, kernel_size=5, padding='valid',\n",
    "                          kernel_initializer=init, activation='relu')(px1)\n",
    "    px2 = tf.layers.MaxPooling2D(2, 2)(x2)\n",
    "    x_flat = tf.layers.Flatten()(px2)\n",
    "    cx1 = tf.layers.Dense(120, activation='relu', kernel_initializer=init)(x_flat)\n",
    "    cx2 = tf.layers.Dense(84, activation='relu', kernel_initializer=init)(cx1)\n",
    "    cx3 = tf.layers.Dense(10, kernel_initializer=init)(cx2)\n",
    "    y_pred = tf.nn.softmax(cx3)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=cx3)\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "    accuracy = calculate_accuracy(y, y_pred)\n",
    "\n",
    "    return y_pred, train_op, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epochs: 3.4002912044525146 cost, 0.09901999682188034 accuracy, 3.400012493133545 validation cost, 0.09669999778270721 validation accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m         X_batch \u001b[38;5;241m=\u001b[39m X_shuffle[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     31\u001b[0m         Y_batch \u001b[38;5;241m=\u001b[39m Y_shuffle[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 32\u001b[0m         \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m cost, accuracy \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun((loss, acc), feed_dict\u001b[38;5;241m=\u001b[39m{x:X_train_c, y:Y_train})\n\u001b[1;32m     34\u001b[0m cost_valid, accuracy_valid \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun((loss, acc), feed_dict\u001b[38;5;241m=\u001b[39m{x:X_valid_c, y:Y_valid})\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    968\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1190\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1191\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:1368\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1369\u001b[0m                        run_metadata)\n\u001b[1;32m   1370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:1375\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[1;32m   1374\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1376\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1377\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:1359\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1357\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1359\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1360\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[0;32m~/.env/holbertonschool-machine_learning-zF0IEfUY/lib/python3.8/site-packages/tensorflow/python/client/session.py:1451\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1451\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1452\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.disable_eager_execution()\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "Y_train = lib['Y_train']\n",
    "X_valid = lib['X_valid']\n",
    "Y_valid = lib['Y_valid']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "X_valid_c = X_valid.reshape((-1, h, w, 1))\n",
    "x = tf.placeholder(tf.float32, (None, h, w, 1))\n",
    "y = tf.placeholder(tf.int32, (None,))\n",
    "y_oh = tf.one_hot(y, 10)\n",
    "y_pred, train_op, loss, acc = lenet5(x, y_oh)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "        cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "        print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epoch, cost, accuracy, cost_valid, accuracy_valid))\n",
    "        p = np.random.permutation(m)\n",
    "        X_shuffle = X_train_c[p]\n",
    "        Y_shuffle = Y_train[p]\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffle[i:i+batch_size]\n",
    "            Y_batch = Y_shuffle[i:i+batch_size]\n",
    "            sess.run(train_op, feed_dict={x:X_batch, y:Y_batch})\n",
    "    cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "    cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epochs, cost, accuracy, cost_valid, accuracy_valid))\n",
    "    Y_pred = sess.run(y_pred, feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(Y_pred[0])\n",
    "    Y_pred = np.argmax(Y_pred, 1)\n",
    "    plt.imshow(X_valid[0])\n",
    "    plt.title(str(Y_valid[0]) + ' : ' + str(Y_pred[0]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('holbertonschool-machine_learning-zF0IEfUY')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1bb7f88ff86f8a65293f6958f33bcf6ed9c9a574270708a89302acb2663e3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
