{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85fa9ba-ce1f-492e-b2af-e3f736417f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 18:38:47.906623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-13 18:38:47.906641: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12f234a7-2831-4d01-9541-18e5d7ac9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    \"\"\"\n",
    "    Build a neural network with the Keras library\n",
    "\n",
    "    nx is the number of input features to the network\n",
    "\n",
    "    layers is a list containing the number of nodes\n",
    "    in each layer of the network\n",
    "\n",
    "    activations is a list containing the activation\n",
    "\n",
    "    functions used for each layer of the network\n",
    "\n",
    "    lambtha is the L2 regularization parameter\n",
    "\n",
    "    keep_prob is the probability that a node will\n",
    "    be kept for dropout\n",
    "\n",
    "    You are not allowed to use the Input class\n",
    "\n",
    "    Returns: the keras model\n",
    "    \"\"\"\n",
    "    model = K.Sequential()\n",
    "    for i, layer in enumerate(layers):\n",
    "        l2 = K.regularizers.L2(lambtha)\n",
    "        if i == 0:\n",
    "            model.add(K.layers.Dense(layer, input_shape=(nx,),\n",
    "                                     activation=activations[i],\n",
    "                                     kernel_regularizer=l2))\n",
    "        else:\n",
    "            model.add(K.layers.Dense(layer, \n",
    "                                     activation=activations[i],\n",
    "                                     kernel_regularizer=l2))\n",
    "        if i != len(layers)-1:\n",
    "            model.add(K.layers.Dropout(1-keep_prob))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd64eda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=0.38640815>, <tf.Tensor: shape=(), dtype=float32, numpy=0.25695384>, <tf.Tensor: shape=(), dtype=float32, numpy=0.019414766>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 18:38:58.414279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-13 18:38:58.414316: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-13 18:38:58.414347: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archpc): /proc/driver/nvidia/version does not exist\n",
      "2022-09-13 18:38:58.414648: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Force Seed - fix for Keras\n",
    "SEED = 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db066013",
   "metadata": {},
   "source": [
    "# You are not allowed to use the Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff137fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    \"\"\"\n",
    "    Build a neural network with the Keras library\n",
    "\n",
    "    nx is the number of input features to the network\n",
    "\n",
    "    layers is a list containing the number of nodes in\n",
    "    each layer of the network\n",
    "\n",
    "    activations is a list containing the activation functions\n",
    "    used for each layer of the network\n",
    "\n",
    "    lambtha is the L2 regularization parameter\n",
    "\n",
    "    keep_prob is the probability that a node will be kept for dropout\n",
    "    Returns: the keras model\n",
    "    \"\"\"\n",
    "    prev = K.Input(shape=(nx,))\n",
    "    inputs = prev\n",
    "    l2 = K.regularizers.L2(lambtha)\n",
    "    for i, layer in enumerate(layers):\n",
    "        prev = K.layers.Dense(layer, activation=activations[i], kernel_regularizer=l2)(prev)\n",
    "        if i != len(layers) - 1:\n",
    "            prev = K.layers.Dropout(keep_prob)(prev)\n",
    "\n",
    "    model = K.Model(inputs=inputs, outputs=prev)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69007df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 19:42:56.579719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-13 19:42:56.579739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=0.38640815>, <tf.Tensor: shape=(), dtype=float32, numpy=0.25695384>, <tf.Tensor: shape=(), dtype=float32, numpy=0.019414766>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 19:42:57.975802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-13 19:42:57.975827: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-13 19:42:57.975852: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archpc): /proc/driver/nvidia/version does not exist\n",
      "2022-09-13 19:42:57.976057: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Force Seed - fix for Keras\n",
    "SEED = 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "258a4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(network, alpha, beta1, beta2):\n",
    "    \"\"\"\n",
    "    sets up Adam optimization for a keras model with\\\n",
    "    categorical crossentropy loss and accuracy metrics.\n",
    "\n",
    "    network is the model to optimize\n",
    "    alpha is the learning rate\n",
    "    beta1 is the first Adam optimization parameter\n",
    "    beta2 is the second Adam optimization parameter\n",
    "    Returns: None \n",
    "    \"\"\"\n",
    "    optimizer = K.optimizers.Adam(alpha, beta1, beta2)\n",
    "    network.compile(optimizer=optimizer,\n",
    "                    loss=K.losses.CategoricalCrossentropy(),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd72b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.losses.CategoricalCrossentropy'>\n",
      "<class 'keras.optimizer_v2.adam.Adam'>\n",
      "(0.01, 0.99, 0.9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    optimize_model(model, 0.01, 0.99, 0.9)\n",
    "    print(model.loss)\n",
    "    opt = model.optimizer\n",
    "    print(opt.__class__)\n",
    "    print(tuple(map(lambda x: x.numpy(),(opt.lr, opt.beta_1, opt.beta_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475ef9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, classes=None):\n",
    "    \"\"\"One hot encoding keras.\"\"\"\n",
    "    if classes is None:\n",
    "        classes = max(labels) + 1\n",
    "    layer = K.layers.CategoryEncoding(\n",
    "        num_tokens=classes, output_mode=\"one_hot\")\n",
    "    return layer(labels).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59be1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    labels = np.load('../data/MNIST.npz')['Y_train'][:10]\n",
    "    print(labels)\n",
    "    print(one_hot(labels))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edafce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(network, data, labels, batch_size, epochs,\n",
    "                verbose=True, shuffle=False):\n",
    "    \"\"\"\n",
    "    Train Keras Model.\n",
    "\n",
    "    network is the model to train\n",
    "\n",
    "    data is a numpy.ndarray of shape (m, nx) containing the input data\n",
    "\n",
    "    labels is a one-hot numpy.ndarray of shape (m, classes)\n",
    "     containing the labels of data\n",
    "\n",
    "    batch_size is the size of the batch used for mini-batch gradient descent\n",
    "\n",
    "    epochs is the number of passes through data for mini-batch gradient descent\n",
    "\n",
    "    verbose is a boolean that determines if output should be\n",
    "    printed during training\n",
    "\n",
    "    shuffle is a boolean that determines whether to\n",
    "    shuffle the batches every epoch.\n",
    "\n",
    "    Normally, it is a good idea to shuffle, but for reproducibility,\n",
    "    we have chosen to set the default to False.\n",
    "\n",
    "    Returns: the History object generated after training the model\n",
    "    \"\"\"\n",
    "    history = network.fit(data, labels, batch_size, epochs,\n",
    "                          verbose=verbose, shuffle=shuffle)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f953ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 22:17:45.125496: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3256 - accuracy: 0.9210\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1409 - accuracy: 0.9754\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1249 - accuracy: 0.9803\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras as K\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datasets = np.load('../data/MNIST.npz')\n",
    "    X_train = datasets['X_train']\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    Y_train = datasets['Y_train']\n",
    "    Y_train_oh = one_hot(Y_train)\n",
    "\n",
    "    lambtha = 0.0001\n",
    "    keep_prob = 0.95\n",
    "    network = build_model(784, [256, 256, 10], ['relu', 'relu', 'softmax'], lambtha, keep_prob)\n",
    "    alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    optimize_model(network, alpha, beta1, beta2)\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    train_model(network, X_train, Y_train_oh, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88f268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, data, labels, batch_size, epochs,\n",
    "                validation_data=None, verbose=True, shuffle=False):\n",
    "    \"\"\"\n",
    "    Train Keras Model.\n",
    "\n",
    "    network is the model to train\n",
    "\n",
    "    data is a numpy.ndarray of shape (m, nx) containing the input data\n",
    "\n",
    "    labels is a one-hot numpy.ndarray of shape (m, classes)\n",
    "     containing the labels of data\n",
    "\n",
    "    batch_size is the size of the batch used for mini-batch gradient descent\n",
    "\n",
    "    epochs is the number of passes through data for mini-batch gradient descent\n",
    "\n",
    "    verbose is a boolean that determines if output should be\n",
    "    printed during training\n",
    "\n",
    "    shuffle is a boolean that determines whether to\n",
    "    shuffle the batches every epoch.\n",
    "\n",
    "    Normally, it is a good idea to shuffle, but for reproducibility,\n",
    "    we have chosen to set the default to False.\n",
    "\n",
    "    Returns: the History object generated after training the model\n",
    "    \"\"\"\n",
    "    history = network.fit(data, labels, batch_size, epochs,\n",
    "                          verbose=verbose, shuffle=shuffle,\n",
    "                          validation_data=validation_data)\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d85df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 22:22:51.813670: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3256 - accuracy: 0.9210 - val_loss: 0.1889 - val_accuracy: 0.9628\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.9658 - val_loss: 0.1586 - val_accuracy: 0.9700\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1409 - accuracy: 0.9754 - val_loss: 0.1555 - val_accuracy: 0.9724\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1249 - accuracy: 0.9803 - val_loss: 0.1529 - val_accuracy: 0.9738\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1147 - accuracy: 0.9839 - val_loss: 0.1510 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Force Seed - fix for Keras\n",
    "SEED = 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datasets = np.load('../data/MNIST.npz')\n",
    "    X_train = datasets['X_train']\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    Y_train = datasets['Y_train']\n",
    "    Y_train_oh = one_hot(Y_train)\n",
    "    X_valid = datasets['X_valid']\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "    Y_valid = datasets['Y_valid']\n",
    "    Y_valid_oh = one_hot(Y_valid)\n",
    "\n",
    "    lambtha = 0.0001\n",
    "    keep_prob = 0.95\n",
    "    network = build_model(784, [256, 256, 10], ['relu', 'relu', 'softmax'], lambtha, keep_prob)\n",
    "    alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    optimize_model(network, alpha, beta1, beta2)\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    train_model(network, X_train, Y_train_oh, batch_size, epochs, validation_data=(X_valid, Y_valid_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a13d810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, data, labels, batch_size, epochs, \n",
    "                validation_data=None, early_stopping=False, \n",
    "                patience=0, verbose=True, shuffle=False):\n",
    "    \"\"\"\n",
    "    Train Keras Model.\n",
    "\n",
    "    network is the model to train\n",
    "\n",
    "    data is a numpy.ndarray of shape (m, nx) containing the input data\n",
    "\n",
    "    labels is a one-hot numpy.ndarray of shape (m, classes)\n",
    "     containing the labels of data\n",
    "\n",
    "    batch_size is the size of the batch used for mini-batch gradient descent\n",
    "\n",
    "    epochs is the number of passes through data for mini-batch gradient descent\n",
    "\n",
    "    verbose is a boolean that determines if output should be\n",
    "    printed during training\n",
    "\n",
    "    validation_data is the data to validate the model with, if not None\n",
    "\n",
    "    early_stopping is a boolean that indicates whether early stopping should be used\n",
    "\n",
    "    patience is the patience used for early stopping\n",
    "\n",
    "    shuffle is a boolean that determines whether to\n",
    "    shuffle the batches every epoch.\n",
    "\n",
    "    Normally, it is a good idea to shuffle, but for reproducibility,\n",
    "    we have chosen to set the default to False.\n",
    "\n",
    "    Returns: the History object generated after training the model\n",
    "    \"\"\"\n",
    "    if validation_data:\n",
    "        early_stopping_callback = K.callbacks.EarlyStopping(\n",
    "            'val_loss', patience=patience)\n",
    "    history = network.fit(data, labels, batch_size, epochs,\n",
    "                          verbose=verbose, shuffle=shuffle,\n",
    "                          validation_data=validation_data,\n",
    "                          callbacks=early_stopping_callback)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c5a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3256 - accuracy: 0.9210 - val_loss: 0.1889 - val_accuracy: 0.9628\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1748 - accuracy: 0.9658 - val_loss: 0.1586 - val_accuracy: 0.9700\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1409 - accuracy: 0.9754 - val_loss: 0.1555 - val_accuracy: 0.9724\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1249 - accuracy: 0.9803 - val_loss: 0.1529 - val_accuracy: 0.9738\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.9839 - val_loss: 0.1510 - val_accuracy: 0.9748\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1105 - accuracy: 0.9850 - val_loss: 0.1416 - val_accuracy: 0.9764\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1015 - accuracy: 0.9873 - val_loss: 0.1860 - val_accuracy: 0.9653\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1007 - accuracy: 0.9869 - val_loss: 0.1438 - val_accuracy: 0.9776\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0989 - accuracy: 0.9879 - val_loss: 0.1471 - val_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Force Seed - fix for Keras\n",
    "SEED = 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "import tensorflow.keras as K\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datasets = np.load('../data/MNIST.npz')\n",
    "    X_train = datasets['X_train']\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    Y_train = datasets['Y_train']\n",
    "    Y_train_oh = one_hot(Y_train)\n",
    "    X_valid = datasets['X_valid']\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "    Y_valid = datasets['Y_valid']\n",
    "    Y_valid_oh = one_hot(Y_valid)\n",
    "\n",
    "    lambtha = 0.0001\n",
    "    keep_prob = 0.95\n",
    "    network = build_model(784, [256, 256, 10], ['relu', 'relu', 'softmax'], lambtha, keep_prob)\n",
    "    alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    optimize_model(network, alpha, beta1, beta2)\n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    train_model(network, X_train, Y_train_oh, batch_size, epochs,\n",
    "                validation_data=(X_valid, Y_valid_oh), early_stopping=True,\n",
    "                patience=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('holbertonschool-machine_learning-zF0IEfUY')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1bb7f88ff86f8a65293f6958f33bcf6ed9c9a574270708a89302acb2663e3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
